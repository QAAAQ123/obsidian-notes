## CNN과정
1. 특징 추출
	1. 합성곱 계층: 지역적 특징 추출
		- 커널,스트라이드,패딩
		- 3차원 합성곱,1x1 합성곱,팽창 합성곱
	2. 풀링 계층: 국소 영역을 하나의 대표값으로 요약
		- 맥스 풀링,평균 풀링
2. 평탄화: 다차원을 1차원으로 변환
3. 분류기: 클래스 예측
	1. fully connected layer:MLP
	2. 소프트맥스

## CNN 모델
1. AlexNet
2. VGGNet
3. ResNet

---

### MLP 한계점
1. **공간정보 손실**: 1차원으로 변형해야 하기때문에 변형 과정에서 픽셀간의 관계가 사라지는 문제 
2. **파라미터 폭증**: 이미지 크기가 커지면 학습에 필요한 파라미터의 수가 기하급수적으로 증가하여 가중치가 매우 많이 필요해진다
3. **위치 불변성 결여**: 같은 패턴이라도 위치가 바뀌면 다르게 해석하는 현상

층: 층은 채널들의 묶음입니다.
입력 --커널--> 출력을 여러번 반복하면 층이 여러개가 쌓여서 신경망이 깊어진다
## CNN(합성곱 신경망)
- **이미지 인식 및 처리**에서 뛰어난 성능을 보이는 신경망 구조
- **특징 추출기와 분류기**로 구성
	- 특징 추출기: 유의미한 특징을 추출
	- 분류기: 특징을 통해서 이미지가 어떤 클래스인지 판별(분류)
	- 특징 추출 -> 평탄화 -> 분류
- 왜 특징 추출을 하는지: **특징 정보는 압축적**이기 때문에 크기가 작아서 **파라미터 폭증 문제 완화 + 관계 정보 포함**
- 합성곱 계층: 지역적 특징 추출,정보 압축
	- 합성곱 계층: 지역적 특징 추출
	- 커널(가중치): 공유 가중치,파라미터
		- **~={red}여러개의 커널을 사용하여 커널마다 다른 특징 학습=~**
	- 스트라이드: 커널 이동시 건너뛰는 픽셀 수/하이퍼파라미터
	- 패딩: 가장자리에 0을 추가/하이퍼파파라미터
		- 가장자리 손실에서 보호
		- 출력 크기 조절
- **~={red}합성곱 후 출력 크기=~** = `[(입력 크기 - 커널 크기 + 2 * 패딩 크기) / 스트라이드] + 1`


### CNN 합성곱 연산 방법
1. 3차원 합성곱 연산: **~={red}공간적 특징 추출=~**
	1. 이미지가 RGB를 가지고 있기 때문에 3차원 형식으로 계산함
	2. 볼륨 단위의 계산
	   3x3x2 커널이 2개 있으면 3x3x2 커널을 2번 계산하여 출력의 채널이 2가 된다
	3. **입력의 채널 수와 커널의 채널수가 동일**해야 한다
2. 1x1합성곱: **~={red}채널수 조절=~**
	1. 공간정보(H x W)는 유지하면서 채널간 관계 학습
	2. 커널의 공간적 크기가 1(C=1)인 연산
	3. 역할: 한개의 픽셀을 한번에 보기 때문에 공간 정보를 유지하지만, 여러개의 채널 정보를 한번에 하나의 값으로 압축을 함 -> 채널간의 관계 학습
	4. 모든 채널 값(C)을 결합하여 새로운 하나의 특징 생성
		1. 연산 결과 채널의 크기는 항상 1이됨->한 채널에 입력의 특징 압축
		2. 필터를 여러 개 사용하여 채널 수를 조절
	5. 특징
		1. 채널수 조절
		2. 비선형성 추가
		3. 채널 간 상호작용
		4. 특징 재조합
3. 팽창 합성곱: **~={red}계층 깊이 감소=~**
	1. 커널에 빈공간을 두는 방법
	2. 커널 크기 키우지 않고 커널이 더 많은 입력 정보 받아들임
	3. 동일 범위를 더 적은 계층으로 처리해서 계층 깊이 감소
		일반 합성곱은 3번 연산(3층)을 해야 볼 수 있는 범위를, 팽창 합성곱은 1번 연산(1층)만으로 볼 수 있습니다.

## CNN 풀링 계층: 대푯값으로 요약
1. 맥스 풀링: 영역의 최댓값 선택
	1. 핵심 패턴 강조
	2. 잡음 억제에 유리
	3. 노이즈에 취약
	4. 세부 정보 손실
2. 평균 풀링: 영역의 평균값 계산
	1. 전반적인 패턴 반영
	2. 노이즈 완화
	3. 잡음이 연산에 포함
	4. 강한 특징이 약화됨

### 평탄화 층
1. 다차원 특징 맵을 1차원으로 펼치는 변환 층
2. MLP의 입력인 1차원 형태로 변환

## 분류기
- 합성곱 계층에서 추출된 특징을 1차원 형태로 받아 클래스 예측
- fully connected layer(MLP)와 소프트맥스로 구성

## CNN 모델
파라미터(커널 수): AlexNet > VGGNet > ResNet
네트워크 깊이: ResNet > VGGNet > AlexNet
1. AlexNet: 시초
	1. CNN 이미지 분류모델 시초
	2. Max pooling 사용
	3. 병렬 GPU 연산(여러대의 GPU 사용)
	4. ReLU 사용: 빠르고 안정적인 학습
	5. 드롭아웃 적용: 정규화
	6. 중첩 풀링: 풀링 영역이 겹치는 방식
	7. AlexNet 단점: 깊지 않은 신경망 구조(**~={red}신경망이 깊지 않다 = 층의 개수가 적다,필터 사이즈가 크다=~**)
2. VGGNet: 3x3커널 사이즈
	1. 신경망을 깊게 만들기 위해 커널의 사이즈를 줄임
	2. 3x3의 고정된 커널 크기로 합성곱을 진행하여 깊게 만들어줌
	3. 작은 필터 사용하면 파라미터(커널)의 수가 줄어들고 합성곱도 많이 해줘야 해서 활성화 함수 더 많이 적용 가능 -> 비선형성 높아짐
	4. 데이터 증강 기법 사용: 랜덤 크롭,좌우 반전,색상 변화
		1. 학습 데이터수 증가
		2. 새로운 분포가 생기기 때문에 과적합 방지 + 일반화 성능 향상
3. ResNet: 병목 구조(1x1,3x3 필터),잔차 학습
	1. VGGNet: 깊은 네트워크 모델에서 기울기 소실 문제가 발생하기 때문에 항상 좋은 성능을 보장하지 못하는 문제
	2. **잔차 학습 도입하여 기울기 소실 문제 해결** -> 깊은 네트워크에서 안정적 학습이 가능해짐
	3. 잔차 학습: 변화량 학습
		1. 스킵 연결: 잔차 학습을 위해서 입력을 출력에 더해주는 구조
		2. Output = Input + x => input = Output - x가 됨
		3. 장점: 입력인 x를 미분하면 항상 1이 나오기 때문에 계속 곱할때 1이라는 값을 더해주게 된다. 1을 계속 더해주기 때문에 기울기가 작아지지 않는다
	4. 병목 구조: 깊은 네트워크에서 효율적인 구조
		1. 1x1 합성곱: 채널 축소하거나 확장
		2. 3x3 합성곱: 핵심 특징 학습


---
## 1. 왜 MLP 대신 CNN을 쓰는가? (등장 배경)

시험에서 "MLP의 한계와 CNN의 장점"을 묻는다면 다음 키워드를 기억하세요.

- **MLP(다층 퍼셉트론)의 한계** 
    1. **공간 정보 손실 (Spatial Information Loss):** 2차원 이미지를 1차원으로 평탄화(Flatten)하면서 픽셀 간의 위치 관계나 지역적 특징이 사라집니다. 
    2. **파라미터 폭증 (Parameter Explosion):** 이미지 크기가 커지면 가중치(Weight) 수가 기하급수적으로 늘어납니다. (예: $800 \times 500$ 이미지라면 입력층만 120만 개의 노드가 필요) 
    3. **위치 불변성 결여 (Lack of Translation Invariance):** 같은 강아지 사진이라도 위치가 조금만 바뀌면 완전히 다른 데이터로 인식합니다.
- **CNN의 해결책**
    - **지역적 특징 학습:** 이미지를 조각(Patch)으로 나누어 지역적인 패턴(Edge, Texture 등)을 학습합니다.
    - **가중치 공유 (Weight Sharing):** 동일한 커널(필터)을 이미지 전체에 적용하므로 파라미터 수를 획기적으로 줄입니다.



## 2. CNN의 핵심 구성 요소 (The Building Blocks)

CNN은 크게 **특징 추출기(Feature Extractor)**와 **분류기(Classifier)**로 나뉩니다. 
① 합성곱 계층 (Convolutional Layer) 
- **역할:** 필터(Kernel)가 이미지를 스캔하며 특징 맵(Feature Map)을 생성합니다.
- **동작:** 입력 데이터와 필터 간의 **성분곱 후 합(Sum of Products)**을 계산합니다. 
- **주요 개념 (★시험 필수★):**
    - **스트라이드 (Stride):** 필터가 이동하는 보폭입니다. 값이 클수록 출력 크기는 작아집니다. 
    - **패딩 (Padding):** 입력 가장자리에 0을 채워(Zero Padding) 출력 크기가 줄어드는 것을 방지하고, 가장자리 정보를 보존합니다. 

② 풀링 계층 (Pooling Layer) 
- **역할:** 중요 정보만 남기고 사이즈를 줄여(Downsampling) 연산량을 감소시키고, 과적합을 방지합니다. 
- **종류:**
    - **Max Pooling:** 구역 내 **최대값** 선택. 텍스처나 가장자리 같은 강한 특징을 보존하며 노이즈에 강합니다. (주로 사용됨) 
    - **Average Pooling:** 구역 내 **평균값** 계산. 전체적인 특징을 부드럽게 반영하지만 특징이 흐려질 수 있습니다.
### ③ 완전 연결 계층 (Fully Connected Layer)
- 추출된 특징 맵을 **평탄화(Flatten)**하여 1차원 벡터로 만들고, 최종 클래스를 분류합니다.
## 3. [★중요] 출력 크기 계산 공식
이 공식은 계산 문제로 자주 나옵니다. 꼭 암기하세요!
$$Output Size = \lfloor \frac{Input - Kernel + 2 \times Padding}{Stride} \rfloor + 1$$
- $Input$: 입력 크기
- $Kernel$: 필터 크기
- $Padding$: 패딩 크기
- $Stride$: 스트라이드 크기


## 4. CNN 아키텍처의 진화 (History)

각 모델이 **무엇을 개선했는지**가 포인트입니다.
1. LeNet-5 19
- CNN의 조상 격인 모델입니다. Conv -> Pool -> FC 구조를 확립했습니다.

1. AlexNet (2012) 21212121
- 딥러닝 붐을 일으킨 모델입니다.
- **핵심 특징:**
    - ReLU 활성화 함수 사용 (학습 속도 개선). 
    - Dropout 적용 (과적합 방지). 
    - GPU 병렬 연산 활용. 
    - 중첩 풀링(Overlapping Pooling) 사용. 

1. VGGNet (2014) 26
- **핵심 아이디어:** **$3 \times 3$의 작은 필터**만 사용하여 깊은 신경망(16~19층)을 쌓았습니다. 
- **시험 포인트:** 왜 $5 \times 5$ 필터 한 번 대신 $3 \times 3$ 필터 두 번을 쓰는가?
    - 수용 영역(Receptive Field)은 동일하지만, **파라미터 수가 감소**하고 **비선형성(ReLU)을 더 많이 추가**할 수 있어 학습 효율이 좋습니다.  
- **$1 \times 1$ Convolution:** 채널 수를 조절(주로 축소)하고 비선형성을 추가하는 역할을 합니다. 

1. ResNet (2015) 
- **문제 제기:** 네트워크가 너무 깊어지면 기울기 소실(Gradient Vanishing) 문제로 오히려 성능이 떨어짐. 
- **해결책:** **잔차 학습(Residual Learning)**과 **스킵 연결(Skip Connection)** 32
    - 공식: $H(x) = F(x) + x$ (입력을 출력에 더해줌) 
    - 이를 통해 역전파 시 기울기가 잘 전달되어 100층 이상의 깊은 모델도 학습이 가능해졌습니다
- **Bottleneck 구조:** $1 \times 1$ Conv를 앞뒤로 배치하여 연산량을 줄이면서 깊이를 쌓는 구조를 제안했습니다. 



## 5. 교수님의 요점 정리 (시험 대비용)
자, 마지막으로 시험장에 들어가기 전 이것만은 꼭 확인하세요
1. **계산 문제:** 입력 크기, 필터, 패딩, 스트라이드가 주어졌을 때 **출력 특징 맵의 크기(W, H)와 채널 수(D)**를 계산할 수 있어야 합니다.
2. **개념 비교:** Max Pooling과 Average Pooling의 차이점, 그리고 $1 \times 1$ Convolution의 역할을 서술할 수 있어야 합니다.
3. **구조 이해:** VGGNet이 왜 작은 필터를 고집했는지, ResNet의 Skip Connection이 왜 기울기 소실 문제를 해결하는지 설명할 수 있어야 합니다.
4. **용어 정의:** Stride, Padding, Receptive Field, Feature Map 등의 용어를 정확히 이해하세요.