### 합성곱 신경망 2-기본적인 합성망의 구조와 개념
1. 3차원 합성곱 연산
	1. 실제는 3차원 연산을 수행
	2. 이미지 데이터가 3차원의 형식을 가지고 있기 때문이다. 
	3. W,H,C(채널) 가지고 있음
	4. 채널의 예시:3채널 RGB
	5. 커널의 채널수: 입력의 채널수와 동일하게
	6. 3차원 볼륨단위로 수행
	7. ~={red}여러개의 커널을 사용하여 여러개의 특징 정보를 얻을 수도 있다.=~
		1. 커널의 개수만큼의 출력이 나온다. -> 커널도 3차원이 된다. 
		2. D=서로 다른 특징 정보
2. 합성곱: 1x1 합성 곱/팽창 합성 곱(CNN의 전체 구조에서 Convolution 층)
3. 1x1 합성곱(Convolution)
	1. 입력크기와 출력크기가 같다
	2. 한번에 하나의 픽셀만 본다
	3. 역할: 한개의 픽셀을 한번에 보기 때문에 공간 정보를 유지하지만, 여러개의 채널 정보를 한번에 하나의 값으로 압축을 함 -> 채널간의 관계 학습
	4. 각 위치마다 **~={red}모든 채널 값을 결합하여 새로운 하나의 특징 생성=~**
	5. 완전 연결 계층과 유사한 역할
	6. 채널 수 조절,비선형성 추가,채널 간 상호작용 및 특징 재조합
4. 1x1 합성곱 필터의 개수에 따라서 출력의 차원이 늘어남(채널 수 변경을 위해서 많이 사용함)
5. 팽창 합성곱
	1. 커널 요소 사이에 일정한 간격을 두어 수행하는 합성곱 연산(필터에 빈공간을 둔다)
	2. 커널의 크기를 키우지 않고도 필터의 수용 영역을 확장 할 수 있음
	3. 동일한 범위를 더 적은 계층으로 처리하여서 계층의 깊이 감소 및 연산량 절감에 효과적
6. 합성곱 계층: 학습되는 가중치를 가지고 정보를 압축/풀링 계층: 학습 가능한 가중치가 없어 연산량을 감소시킨다
7. 풀링 계층: 국고 영역의 값을 하나의 **대표값으로 요약**하는 연산(CNN의 전체 구조에서 Pooling 층)
	1. 특징 맵의 크기 축소 및 연산량 감소
	2. 노이즈 제거
	3. 위치 변화에 대한 불변성 향상-> 인접한 영역을 하나의 대표값으로 표현하기 때문에 약간의 위치 이동이 있더라도 여전히 같은 영역에 존재한다면 출력값이 일정하다
	4. 상위 계층의 수용 영역을 확장시킨다
8. 풀링 연산 방법: 맥스 풀링/average 풀링 -> 상황에 맞춰서 선택
9. 맥스 풀링: 지정된 영역내의 최댓값을 대푯값으로 선택하여 특징 맵 축소
	1. **풀 사이즈 지정**하여 **~={red}영역내의 가장 큰 값을 대푯값으로 사용=~**
	2. 최댓값 선택 -> 강하게 활성화된 특징만 남겨 핵심적인 패턴 강조
	3. 작은 잡음 억제에 유리
	4. 특이값의 억제에는 불리
	5. 최댓값을 제외한 나머지 세부 정보가 손실 됨
10. 평균 풀링: 영역내의 평균값을 계산해서 특징 맵을 축소
	1. 전반적인 값을 부드럽게 반영
	2. 특이값을 완화하지만, 잡음을 연산에 포함하기 때문에 잡음에 약하다
	3. 강한 특징이 희석되거나 흐려질 수 있음
11. 합성곱 층 뒤에 활성화 함수가 위치해서 각 계층에 비선형성 부여해준다.
12. **~={red}convolution층과 Pooling이 번갈아가면서 나오기는 하지만 항상 1:1 비율로 나오는 것이 아니다=~** 
	1. 각 계층간 비율,각 계층의 패팅,커널,스트라이즈는 **하이퍼파라미터**로 설정해줘야 한다-> 처음부터 완벽히 결정하기 어렵기 때문에 **정형화된 구조들을 참고해서 그대로나 약간의 변형을 통해 사용**한다.  
13. 특징 추출기의 출력 구성: 3차원의 형태로 최종 특징이 나옴
14. MLP는 3차원의 입력을 받을 수 없기 때문에 1차원으로 변경해줘야 한다. 그래서 평탄화 작업을 해줘야 한다. 
15. 분류기: 합성곱 계층에서 추출된 특징을 입력으로 받아서 클래스로 예측
	1. 완전 연결층으로 네트워크가 구성됨
	2. 분류문제를 해결해야 하기 때문에 소프트 맥스와 크로스 엔트로피의 조합으로 학습이 됨
---
잘 정립된 합성망의 구조 
1. 대표적인 CNN 모델
	1. 초기에는 컴퓨터 비젼 분야가 더 활발했음
		1. AlexNet
		2. VGG-19
		3. ResNet-152
2. AlexNet
	1. CNN 이미지 분류모델 시초
	2. 이미지 분류 대회에서 우승
	3. Top1: 정답 하나를 예측해서 그게 실제 정답이 맞는지 확인
	4. Top5: 5 순위를 제시해서 그 중에 실제 정답이 있는지 확인
	5. 알렉스넷 이전에는 ML이 더 좋은 성능을 내었음
3. AlexNet 구조
	1. 5합성곱+3 맥스 풀링 + 3 fully 연결 계층으로 구성
	2. conv와 pooling이 번갈아가면서 나오고 마지막에 분류를 위해서 3개의 fully connented layer가 연속으로 나옴
4. 구조2-첫번째 conv
	1. 96개의 필터 사용
	2. 필터 사이즈 11,11,3
	3. 스트라이드 4
	4. 패팅 0
	5. 설계 이유: 실험적(경험적)으로 가장 성느이 좋아서
	6. 출력 차원 = 55
	7. 초기 단계: 선,모서리,코너,색상 등을 학습함/물리적인 특징 학습함
5. 구조3-첫번째 pooling,두번째 conv
	1. pooling 단계
		1. overlapping may pooling(풀링을 할 때 겹치는 부분이 있다): 3x3 
		2. 스트라이드=2 한칸씩 겹치게 됨
		3. 출력: 27
		4. 입력의 채널은 그대로 유지되는 특징을 가지고 있다. 
		5. 네트워크가 깊어질 수록 feature가 줄어들지만, 더 많은 특징 정보를 가지고 있기를 원한다. 따라서 채널의 크기가 늘어난다(filter의 크기가 늘어난다)
	2. conv단계
		1. 이번에는 256개의 filter 사용
		2. filter 사이즈 5,5,96 
		3. 스트라이드 1
		4. 패팅 2
		5. 출력 27
	3. feature: 조금더 디테일한 특성을 학습/조금더 상위 레벨의 특징을 학습한다
6. 구조4-두번째 pooling,세번째 conv
	1. pooling
		1. 입력: 27,27,256
		2. overlapping may pooling(풀링을 할 때 겹치는 부분이 있다): 3x3 
		3. 스트라이드 2
		4. 출력: 13으로 감소
	2. conv
		1. 필터 사이즈: 3,3,256(사이즈 줄임)
		2. 스트라이드 1,패딩 1
		3. 출력 13,13,384
		4. 깊은 특징을 학습하기 위해서 필터크기를 늘림
7. 구조5-네번째 conv
	1. 세번째와 동일한 필터,스트라이드,패팅 -> 입력과 출력의 사이즈가 동일하다
	2. 이미지에 어떤 객체가 있는지 시각적으로 파악 가능
	3. 뒤로 갈수록 점점더 고차원의 정보를 학습하기 때문에 정보,객체 단위의 객체 맵을 형성한다.
8. 구조6-다섯번째 conv
	1. 마찬가지로 네번째와 동일한 필터,스트라이드,패팅 -> 입력과 출력의 사이즈가 동일하다
	2. 다른점 하나: 필터의 개수를 256개로 줄임
	3. 줄이는 이유: 최종 얻은 결과를 fully conntcted layer로 전달해야하는데 마지막 차원이 커지면 fully cl의 가중치 수가 커져서 가중치 수를 줄이기 위해서 
9. 구조7-세번째 pooling
	1. 13x13이 6x6으로 줄어들고 256개의 차원은 그대로 유지
	2. 최종적으로 1000개의 출력
10. AlexNet 특징
	1. 병렬 GPU(여러개의 GPU) 연산 구조 활용: GPU 용량이 적었기 때문에
		1. conv를 여러개의 conv로 나눔
		2. 중간중간에 서로 독립적인 학습을 방지하기 위해 GPU1,2,3.에 출력을 섞어준다.
	2. ReLU 활성화 함수 사용: 그전에는 시그모이드나 다른 활성화 함수를 사용했지만,알렉스 넷에서는 ReLU를 사용하여 더 빠르고 안정적인 학습
	3. 드롭아웃 적용: 드롭아웃 사용하여 정규화
	4. 중첩 pooling 적용: 일부 영역이 겹치는 풀링 사용
11. VGGNet
	1. AlexNet 단점: 깊지 않은 신경망 구조
	2. 네트워크 자체를 깊게 하는 시도->이 당시 GPU와 메모리 한계
	3. 문제점 극복하고 깊은 신경망 구조 만듦: 신경망을 깊게 구현하면서 파라미터의 양을 줄임(필터사이즈를 줄임)
	4. 네트워크를 깊게 만들어주기 위해서 3X3이라는 작은 사이즈의 conv연산을 수행
	5. 필터 사이즈 3X3 고정
12. VGGNet
	1. 3X3의 작은 필터만 사용하여 모델 구성
		1. 더 깊은 네트워크 구현 가능
		2. 더 많은 활성화 함수 사용 가능 -> 비선형성 강화로 표현력 향상
		3. 적은 파라미터수로 계산 효율성 증대
	2. 작은 필터가 유리한 이유
		1. 5X5필터,스트라이드=1 -> 3X3의 결과가 나옴(입력이 7x7일때 )
			1. 총 25개의 파라미터가 필요함
13. 작은 필터가 유리한 이유2
	1. 7x7의 입력에서 3x3의 필터를 사용하여 3x3으로 출력을 줄이는데에 몇개의 파라미터가 필요한가? 7x7 -> 5x5 -> 3x3(2개의 conv 계층 필요)/이때 필요한 파라미터 수: 9+9=18개
	2. 1보다 파라미터의 크기 감소
	3. 2번의 filter를 적용했기 때문에 ReLU도 2번 적용 가능 -> 같은 사이즈의 입,출력임에도 파라미터수도 적고 비선형성도 추가됨
14. VGGNet
	1. 다양한 데이터 증강 기법 활용
		1. 기존 학습 데이터를 일부 변형해서 새로운 학습 샘플 생성하여 학습에 활용하는 기법
		2. VGGNet에서 사용한 데이터 증강 기법
			1. 랜덤 크롭: 사이즈 변경(rescale)후 기존 이미지 크기에 맞춰 일부분을 잘라서 cropping함 -> 사이즈 같지만 여러개의 증강된 이미지 생성
			2. 좌우 반전
			3. 색상 변화
	2. 데이터 증강 기법 사용 이점
		1. 학습 데이터 수 증가->데이터 부족 문제 완화
		2. 새로운 분포 이미지를 만들어서 학습 진행 -> 과적합 문제 방지/일반화 성능 향상
15. ResNet: 깊은 네트워크의 기울기 소실 문제를 해결하기 위한 방법
	1. VGGNet: 근본적인 문제 해결 못함,여전히 네트워크 깊이를 늘이면 기울기 소실 문제가 발생한다. 깊어질수록 역전파 과정에서 기울기가 계속 곱해져서 기하급수적으로 작아진다/역전파 과정에서 출력층으로 갈수록 신호가 약해진다/훈련 오차가 오히려 증가하는 현상 발생 -> 더 깊은 모델이 항상 좋은 성능을 보장하지 않음
	2. 효율적인 네트워크 구조 설계의 필요성이 제기됨 
	3. 학습과 테스트 에러 모두 높은 -> 과적합 문제가 아니라 학습 과정 자체가 잘 안된다
16. ResNet: 잔차 학습과 스킵 연결이 핵심
	1. 잔차 학습 개념을 도입하여 기울기 소실 문제 해결-> 근본적으로 기울기 소실 문제 해결
	2. 잔차 학습 개념을 스킵 연결을 통해서 구현하여 깊은 네트워크에서 안정적인 학습 가능해짐
	3. 매우 깊은 네트워크에서도 안정적인 학습 가능해짐
17. 잔차 학습과 스킵 연결
	1. 잔차 학습: 입력 자체가 아닌 변화량(잔차)를 학습하는것
	2. 스킵 연결: 잔차 학습을 구현하기 위해서 입력을 출력에 직접 더해주는 연결 구조
	3. 오른쪽이 스킵 연결이다
	4. 출력을 F(x)로 설정 = 왼쪽의 H(x)
	5. X(입력값)을 다른 경로로 가져와서 결괏값에 더해줌
	6. 최종 결과값이 H(x) = F(x) + x가됨
	7. F(x) = H(x) - x,즉 F(x)는 입력값과 출력값의 차이
	8. 결론: 이 네트워크는 **~={red}출력값 자체를 학습하는게 아니고 잔차를 학습=~**한다
18. 잔차 학습의 장점
	1. 미분
	2. x를 x로 미분하면 항상 1이다. 계속해서 곱할때 계속 1이라는 값을 더하기 때문에 기울기가 작아지지 않음(**~={red}기울기 소실 문제 완화=~**)
19. ResNet의 병목 구조
	1. 2개의 conv layer 사용
		1. 1x1: 채널 축소,확장
		2. 3x3: 핵심 특징 학습
		3. 예시 256차원 입력 -> 1x1 conv로 64개 필터 사용해서 채널수를 64개로 감소 -> 3x3 conv연산 -> 연산이 끝나면 1x1 conv를 추가해서 다시 256차원으로 늘려줌 => 결과 256 입력을 가지고 3x3 conv 연산을 한것과 동일한 크기의 출력이 나옴(but 가중치 개수 줄여줌/총 파라미터의 개수가 줄어듬)
20. 학습 성능과 파라미터 개수 비교 도표
	1. VGG는 몇개 사용하지 않지만 파라미터 개수를 매우 많이 사용
	2. ResNet은 계층이 더 많아졌지만 파라미터 수가 작아짐 -> 병목 구조 사용하기 때문에