복습
- 마스크된 멀티헤드 어텐션: 디코더 입력간의 관계 학습/인코더 출력은 반영 안함
- 기본 행렬과 -무한대로 마스크된 행렬을 더해서 masked multiweight 만듦
- 출력 투영층은 fully connected layer 사용해서 언어 사전으로 매핑
- 인코더 출력을 k,v벡터로 변환해서 디코더에 들어간다
14-1 생성 모델
- 생성 vs 판별 모델
	- 생성: 데이터 분포 모델링: **분포 학습** => 샘플링해서 새로운 데이터 만들어 낼 수 있다(X=데이터,Y=클래스)
	- 판별: 조건부 확률 모델링: **분류 학습**=>데이터 분류하는 경계 찾는 것(앞서 계속 공부한 것들)
- 생성 모델: 확률 분포 모델링 => 새 샘플 생성
	- 훈련 데이터와 비슷한 것 생성
- 생성 모델 분류
	- 명시적 밀도 추청: 확률 밀도 함수(수식)을 정의 => 새로운 샘플 나올 확률 계산
	- 암시적 밀도 추청: 수식을 정의하지 않고, 모델이 알아서 생성함,모델 자체만 학습
- 명시적 모델1: Pixel RNN
	- 이전 픽셀 정보 기반으로 다음 확률 예측
	- 이전 정보로 다음 정보 예측: auto regressive 모델
- 명시적 모델2: Pixel CNN
	- 합성 곱으로 다음 값 예측
	- 마스킹된 필터 사용
- Pixel CNN/RNN 단점
	- 순차 생성이기 때문에 병렬 처리 불가,샘플링 생성 속도 느림
	- 장기의존성 학습이 어려움
	- 깊은 모델 필요 => 메모리와 연산량 증가
- 오토 인코더
	- 목표: 핵심 특징 학습
	- 입력보다 낮은 차원 가져야함
	- 인코더: z라는 잠재 표현으로 압축
	- 디코더: z를 이용해서 x햇 으로 복원
	- x와 z의 차이를 줄이도록 학습
	- 비지도 학습

- 인코더: CNN구조 사용
- Fully connected 사용하여 차원 압축 -> z출력(10차원)
- 디코더: 전치 합성곱(작은 차원에서 큰 차원으로 확장)을 통해서 원본 이미지로 복원
- 전치 합성곱
	- 1x1을 3x3 커널을 써서 3x3으로 확장해줌
	- 스트라이드가 커지면 중복이 작아진다
- 오토 인코더: 생성이 아니고 복원만 하기 때문에 생성 모델이 아님
	- 미세 조정하면서 다운 스트림 수행
- 분류기가 있어야 z를 분류 가능 -> 변분 오토 인코더??
- z값의 정규분포에서 어떤 데이터를 가져오는지에 따라 다른 것이 생성된다
- x를 z의 확률분포로 변환한 다음 x로 다시 생성
- 평균과 분산 이용하여 정규분포를 그린다
- 24p. 각 차원의 평균,분산 값 예측 -> 정규 분포 그림
- 원본 이미지와 약간 다른 이미지 생성
- 입력x->인코더 네트워크 ->z의 평균과 분산 예측 ->정규분포 만듦->하나의 값만 샘플링(z)->입력 데이터 x의 분포도 예측->x의 평균,분산 예측->x의 정규분포 만듦->최종 xhat값 예측
- 실제에서는 z,x는 평균값만 구함 => 분산 구하면 노이즈가 심해져서
- 실제에서는 평균과 동일한 차원만 나옴
- 실제 학습
	- p(x)는 실제 학습하기가 어려워 ELBO 사용하여 P(x)근사함
	- ELBO최적화
	- x와 디코더 출력의 평균의 차이가 가장 적게 함
	- KL:p(x)와 p(z)의 차이가 작아질 수록 KL이 작아짐
---
- 딥러닝 모델
	- 생성 모델:분포 자체를 모델링해서 
	- 판별 모델: 조건부 확률 모델링-어떤 클래스에 속하는지 확률
- 생성 모델
	- 단계: 학습 데이터 분포 모델링 -> 분포를 이용해서 새로운 데이터 생성
	- 학습 -> 샘플링(생성)
	- 학습을 통해 P_model(x)를 생성한다
- P_model(x) 생성 방식
	- 명시적 밀도 추정: 확률밀도 함수 명시적으로 정의하고 확률 직접 계산 가능(VAE,PixelRNN,PixelCNN)
	- 암시적 밀도 추정: 확률밀도 함수 명시적으로 정의하지 않고, 직접 계산 불가능
- PiexlRNN
	- RNN기반
	- 명시적 정의
	- 이전 픽셀 정보를 기반으로 다음 픽셀의 확률 분포 예측
	- 순차적으로 생성
	- 한칸씩 이동하면서 다음 픽셀의 확률값을 예측
- PixelCNN
	- 마스킹 CNN기반
	- 이전 픽셀 정보를 기반으로 다음 픽셀의 확률 분포 예측
	- CNN **필터를 통해서 다음값 예측**
	- 픽셀 이후의 값을 연산에 활용하지 않기 위해서 필터를 마스킹함
- PixelCNN,RNN 한계점
	- 픽셀 순차적 생성 -> (이전 정보 활용해야 하기 때문에)병렬 처리 불가 -> 샘플링 속도가 매우 느림
	- 장기 의존성 학습이 어려움 -> 데이터의 전역 구조 표현 설명하기 어려움
	- 깊은 모델이 필요하여 메모리,연산량 많이 필요
- 변분 오토인코더:잠재변수 도입해서 극복
- 오토 인코더
	- 입력 데이터를 작은 차원으로 압축해서 핵심적 특징 학습
	- **전치 합성곱을 이용해서 복원**
	- 압축 -> 복원
	- 차원이 매우 작아지기 때문에, 원본의 매우 중요한 핵심 특징이 들어있어야 한다
	- 원본 데이터를 복원하는 데에만 쓰이기 때문에 추가적인 계층이 필요없다
	- 클래스를 분류하는 계층이 없기 때문에 비지도 학습이다
	- 전치 합성곱 이용해서 원본으로 복원한다(합성곱 연산 반대로: 작은 공간 -> 큰 공간)
		- 하나의 점에서 필터만큼 연산해서 넓은 공간을 만들어냄
		- 스트라이드 키울수록 출력 공간이 커짐
	- 생성 불가(복원만 가능): 새로운 데이터를 만들어 낼 수 없기 때문에
- 오토 인코더
	- 미세 조정하여 다양한 다운스트림 작업 하는 곳에 사용
	- 다운스트림: 사전학습된 모델이 최종적으로 해결하는 목표 작업(여기서는 분류)
	- 미세조정: 다운스트림에 맞춰서 업데이트
	- z라는 특징을 뽑아낼 수 있도록 사전 학습을 통해서 학습을 미리 진행해 놓을 수 있다. 이때 분류성능이 좋아진다
	- VA: 입력 데이터를 한 점에 대응하는 것이 아닌 입력 데이터의 확률 분포에 대응하게 해서 복원과 생성할 수 있다

### 변분 오토인코더(VA)
- **~={red}인코더 -> 표준 정규 분포(잠재 표현 공간) -> 샘플링 -> 디코더=~**
- 입력 데이터를 확률적 잠재 공간으로 인코딩 하고, 잠재 공간으로부터 새로운 데이터 샘플링(점이 아닌 공간)
	- 정규분포 형태로 확률분포를 모델링한다. 여기서 샘플링하는 방식
	- 연속적인 확률 분포이기 때문에, 부드럽고 자연스러운 생성
- VA 확률 분포 2개
	- 잠재 공간 자체의 확률 분포
	- 잠재 변수 z로 부터 x데이터를 생성할 확률
	- 2개 합해서 전체 x에 대한 확률 분포라고 한다
- 구체적인 모델 구조: 인코더,디코더
	- 인코더: 합성곱
	- 디코더: 전치 합성곱
	- **오토인코더와 차이점: 잠재 공간을 정규 확률 분포로 표현**
		- 정규 확률 분포를 알기 위해서는 확률과 분산을 알고 있어야 한다
		- 그래서 잠재 공간에서는 각 차원마다 평균,분산 값을 가진다
		- 차원이 10개이더라도 실제로는 평균,분산 값을 가져야 하기 때문에 20개의 값을 가진다(각 차원의 분산,각 차원의 평균)
	
- 인코더 과정:각 차원의 평균,분산 구함 -> 각 차원마다 표준 정규 분포 구함 -> 서로 다른 정규 분포 생성
- 샘플링 과정: 각 차원의 정규분포에서 하나의 값을 뽑음 -> 샘플링 특징 생성됨
- 디코더 과정: 샘플링된 값을 가지고 디코딩함
- 데이터가 유사한 형태를 유지하게 하기 위해서 차이가 줄어들도록 인코더와 디코더를 모두 한번에 학습: Reconstruction Loss
- 실제에서 디코더는 평균값만 구한다. -> 디코더의 평균만 가지고 x_hat을 생성한다
	- 이유1. 학습의 안정성을 높히기 위해서
	- 이유2. 불필요한 노이즈 감소를 위해서
	- z가 똑같다면, 디코더의 평균이 똑같아서 동일한 샘플링을 생성한다
	- **z값이 결정되면 출력도 결정된다** -> 하지만 z값 자체가 확률이기 때문에 임의의 출력값이 생성이 된다

#### ELBO
- 생성 모델을 학습한다는 것은 log(p_thea(x))를 최대화 하는 것과 동일하다. x를 더 잘 예측하는 것이 목적이기 때문에
- 왼쪽 수식을 크게 하면 자동으로  log(p_thea(x)))도 커지기 때문에, 왼쪽 수식만 커지게 하면 된다
- 2가지 항으로 나뉜다
	- 재구성 항: 인코더부터 출력하는 과정
	- 정규화 항(KL): KL >= 0,출력과 예측 확률 분포의 차이
		- 실제 출력과 예측이 같으면 0이 된다
		- 불일치가 커질수록 KL값이 커진다
		- 재구성 항에서 z가 어떤 분포를 가지고 있는지는 표현하지 않았다 -> 이게 정규화 항
		- 정규 분포를 정의하고  
	- 재구성항은 커저야 하고, 정규화 항은 작아져야 한다(재구성항 - 정규화 항이기 때문에)
- VAE의 문제
	- z를 샘플링 할 때 임의의 값을 뽑기 때문에 확률적이기 때문에 미분 불가능하다
	- 동일한 입력에도 출력이 달라져서 입력,출력간의 관계에 대한 연속 함수를 만들 수 없음 -> 미분 불가능 -> 역전파 불가능 -> 학습 불가능
	- **재파라미터화 트릭**을 이용해 미분 가능한 형태로 변환해줘야 한다.
- 재파라미터화 트릭
	- 입실론: 정규분포에서 샘플링된 값
	- 수식으로 표현(결과 값으로 표현)
	- 기존: z-랜덤/평균과 분산-확정
	- 이후: z,평균,분산-확정/입실론-랜덤
		- 입실론은 역전파가 안돼도 상관없다
- VAE 특징
	- 해석 가능한 잠재공간을 학습하여 데이터의 의미적 변화를 직접 조작 가능
		- z1은 표정,z2는 각도 표현
	- 잠재변수 샘플링으로 샘플을 생성해서 생성 속도가 빠름
	- 단점: 평균 기반으로 복원을 해서 흐릿한 샘플을 생성한다

### 적대적 생성 신경망(GAN)
- VAE 한계점
	- 실제의 고차원 및 복잡한 데이터 분포를 명시적으로 모델링하기 어려움
	- 평균 기반으로 흐릿한 이미지 생성함
- 실제와 유사해보이는 샘플 생성에 집중-> 암시적 
- 단순한 잠재 분포를 입력으로 받아서 실제 데이터와 유사한 샘플을 생성하도록 학습
	- 생성자는 분포에 관심이 없음
- **선명한 이미지 생성 가능**
- 구조: 생성자,판별자 2개의 모듈
	- 생성자: 랜덤 노이즈z를 입력으로 받아서 실제와 유사한 데이터를 생성하는 역할
		- 판별자가 구분하기 어렵도록 학습
	- 판별자: 생성되거나 실제인 데이터를 받아서 진짜인지 가짜(생성자가 만들어낸 것)인지 판별
		- 생성자가 생성한 데이터와 실제 데이터를 잘 구분하도록 학습
	- 생성자와 판별자가 적대적으로 학습을 하기 때문에 적대적 생성 신경망
- 학습 과정
	- 랜덤 노이즈 입력을 생성자를 이용해서 가짜 이미지 만듦
	- 판별자는 가짜 이미지와 실제 이미지를 입력으로 받아서 분류 작업 수행
		- 틀림 -> 역전파 과정으로 학습(판별자(분류 잘하도록) -> 생성자(분류 못하도록))
		- 실제 이미지쪽으로도 역전파 과정 일어남
- 서로 상반된 목표를 얻기 위해서는 목적 함수를 정의해야 한다
	- 최소-최대 목적 함수: 제로섬 게임을 수학적으로 표현한 것
		- 상반된 목표로 경쟁하여 최적화되도록 하는 목적 함수
	- 실제 데이터가 들어왔을때 판별자는 아무것도 안하고 0이 됨
	- 교대 학습함
		- 생성자와 판별자 교대로 업데이트
		- 초기 기울기 소실을 완화하기 위해서 대체 목적 함수를 사용하여 **생성자를 학습**:생성 초기에는 이미지의 질이 낮아서 0에 가까운 값이 나오기 때문에
- 장점
	- 선명하고 현실적인 데이터 생성
	- 구조적 잠재공간을 학습하여 직관적이고 고수준 속성별 조작이 가능
- 단점
	- 손실이 수렴하지 않고 계속 진동(적대적으로 학습하기 때문에)
	- 모드 붕괴: 생성자가 소수의 패턴만 반복적으로 생성해서 샘플 다양성 크게 감소