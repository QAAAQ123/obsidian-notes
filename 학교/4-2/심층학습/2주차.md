1. 초기 인공지능: 기울기 문제/규칙을 모두 작성해야 함/퍼셉트론이 잘 되지 않음
2. 딥러닝 조건: 뉴럴 네트워크와 특징 추출을 스스로 학습
	1. 오래걸리고 학습 데이터도 많지만 성능이 더 좋음
3. 퍼셉트론
	1. 신경망의 기본 단위
	2. 여러개의 퍼셉트론이 모여 딥러닝을 함
	3. 인공 뉴런 모델
4. 뉴런
	1. 서로 상호 연결
	2. 수상돌기에서 전기 신호 받음
	3. 받은 신호 기반으로 다른 뉴런에게 전달
5. 퍼셉트론 전달 과정
	1. 다른 퍼셉트론에서 받은 결과값을 입력으로 받음(뉴런의 수상돌기 부분)
	2. 가중치 곱해줌
	3. 활성 함수: 값을 넘겨줄지 안넘겨 줄지 결정
6. 퍼셉트론 구성
	1. 입력: 초기에는 0or1이였지만 현재는 모든 실수 범위 벡터이다
	2. 가중치: 입력 하나마다 하나의 가중치 존재/중요한 것과 덜 중요한 것 구분
		1. 가중치: 모든 실수 범위(양수,0,음수 모두 가능)
	3. 선형 결합: 모두 더함$$ \sum_{i} x_i w_i $$
	4. 활성함수: 임계치 넘었는지 확인,θ넘으면 1,안넘으면 0 
	5. 입력 -> 가중치 X 입력 -> sum(가중치X입력) -> 활성함수로 판단
7. 8page 예시 1X1 + 0 X 1 = 1/1<θ 따라서 값 전달하지 않음
8. w를 구할때는 임의의 값을 넣어서 계산 해야함
9. 쓰레스 홀드(Threshold,θ)에 따라 w 값도 변함 -> θ와 w를 둘 다 찾아야 함
10. $$y = \sum_{i} w_{i}x_{i} > θ => \sum_{i} w_{i}x_{i} - θ > 0 => \sum_{i} w_{i}x_{i} + b > 0$$
	1. **~={red}여기서 b는 바이어스(편향)로 `b=-θ`이다=~**
	2. 선형 방정식을 완성하는 것은 w와 b를 구하는 것=>퍼셉트론을 완성하는 것
11. OR연산 많은 경우의 수가 있음
12. ★★분류기★★
	1. 분류 기준: 경계 결정
	2. ★★★퍼셉트론은 선형 분류기임(직선 밖에 분류 못함)★★★
	3. 따라서 퍼셉트론으로 XOR은 문제해결 불가
	4. w와 b값에 따라서 선형 결정 경계가 이동한다
13. 그림 1:and,2:or,3:XOR(XOR은 비선형 경계)
    xor은 비선형 결정 경계로만 분류할 수 있다
14. 학습
	1. w와 b는 모델이 스스로 학습한다.
	2. 퍼셉트론에서 파라미더 = 가중치와 b
	3. **편향과 가중치를 하나로 만들어서 계산하면 편하다**
	4. **~={red}편향을 입력값이 1인 가중치로 생각=~**
	5. $$\sum_{i} w_{i}x_{i}+b를 \sum_{i}  w_{i}x_{i}+w_{0}*1$$로 생각한다
	6. b를 가중치가 w_0이고 입력값이 1인 것으로 변경했다
15. 학습 데이터
	1. 입력값,출력값 가지고 있어야 함
	2. input x는 2차원 특징 벡터
	3. target은 정답 값
	4. 퍼셉트론은 입력,정답만 알 수 있음
16. Targe: 목표값/Output: 실제 결과 값
	1. Target과 output이 다른거: 오차 -> 오차를 줄이는 방향으로 학습
	2. 입력 데이터 들어옴 -> 예상 값 계산 -> 실제 값 계산 -> 예상과 실제 비교-> 오차 줄이는 방향으로 학습
17. 학습 규칙-여기서부터 모르겠음???
	1. 오차 방향으로 가중치 업데이트
	2. 에타(η):학습률: 오차를 빠르게 or 느리게 수정할지 결정하는 수 0<η<1
	3. Δw = 학습률(오차) 입력값 = η(targe-0)*x
	4. η가 클수록 Δw가 커짐

--- 
## 동영상 강의
- 선형 함수가 임계점 θ를 넘는지 안넘는지에 따라서 전달 여부 결정
- 퍼셉트론: 선형 분류기-> 직선(2차원)/평면(3차원)/초평면(4차원 이상)에서 만 분류가능
- 결정 경계
- w와 b가 변하면 그래프 모양이 변함-> 결정 경계가 변함


### 퍼셉트론 학습
1. w와 b(θ)찾는 과정-> 이 과정을 모델 스스로가 학습
2. $$\sum\limits_{i} w_{i}*x_{i} + b > 0 에서  b = b * 1=w_{0}*x => \sum\limits_{i} w_{i} * x_{i} + w_{0}*1 > 0   $$
3. 목표와 출력의 **오차를 줄이도록** 가중치 조정하는 과정

### 퍼셉트론 학습 규칙
1. target쪽에 가까워지도록 학습
2. $$\varDelta_{w} + w_{구} -> w_{신} 과 \varDelta_{w} = \eta(t-o)*x_{i} $$
3. 예시) o = 0이고 t=1일때 => \varDelta_w = \eta*x_i
	1. case1: x_i 양수일때 => \varDelta = 양수 => 양수 + w_구 => w_신 증가 => w_i x x_i증가(증가x양수) => 양수 방향 증가
	2. case2: x_i 음수일때 => \varDelta = 음수 => 음수 + w_구 => w_신 감소 => w_i x x_i감소(감소x음수) => 음수 감소 방향

### 퍼셉트론 계산 과정
1. 퍼셉트론 초기 출력값 계산
2. 가중치 변화량 계산
3. 가중치 업데이트
4. 수정후 출력값 계산

### 코드 
1. 종료조건: 특정 에러 값에 도달 or 특정 반복 횟수 만큼 반복
2. 오차가 선형적으로 감소하는게 아니라 진동하면서 감소하는 형태
