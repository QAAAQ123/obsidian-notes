### 다층 퍼셉트론
1. 다층 페셉트론의 개념: 여러 층의 퍼셉트론을 쌓아 복잡성을 확보한 신경망
2. 활성함수: 비선형 활성함수임 => 비선형성 부여
3. 결정경계를 비선형적으로 만들 수 있음(다층 퍼셉트론은 비선형 결정경계임)
4. 다층 퍼셉트론이 필요한 이유: 더 다양한 모양의 결정 경계를 얻기 위해 복잡한 모양의 활성화 함수를 얻기 위해
5. 역전파: 오차 기반의 학습으로는 MLP를 학습시키기에 적합하지 않음/MLP를 효율적으로 학습하는 방식 중 하나
6. 다층 퍼셉트론의 구성: 1.입력 2.은닉 3.출력 층으로 구성
	1. 입력: 입력값 받는 층
	2. 은닉: 패턴 파악(은닉층의 구조는 사용자가 결정)
	3. 출력: 결과 출력하는 층
7. 가중치 행렬: 뉴런과 뉴런사이의 연결 강도를 나타내는 행렬
	1. 가중치 개수 = 이전 층 x 다음 층
8. 입력: 은닉층 가중치/은닉: 출력층 가중치 필요: w_1과 w_2
	1. 행: 현재층 뉴런 수
	2. 열: 이전층 뉴런 수
	3. **~={red}현재 x 이전 층의 행렬 형태=~**
	4. w_x,y => x: 현재층,y:이전층
	5. x:입력층 y:은닉층 o:출력층
	6. 계산
	7. GPU 연산을 사용하기 위해 병렬 연산을 사용한다
9. 
10. 페이지10: 여러층의 선형 변환 연산은 하나의 선형연산이 되기 때문에 더 뛰어난 모델이 반드시 더 복잡한 것은 아니다
11. 활성화 함수
	1. 입력의 선형 연산의 결과를 **~={red}비선형적으로 변환=~**하는 함수 ex)sigmoid 함수
12. z^(1)을 복잡한 모양을 변형시킴
13. 활성함수가 누적되면 어떻게 되는지 => 점점더 복잡한 패턴이 만들어짐
14. 다양한 활성화 함수의 종류
15. 역전파
	1. 학습 알고리즘-**~={red}기여도 할당 문제를 해결하기 위해서 사용=~**
	2. 오차를 반대 방향으로 전파하여 역전파
	3. 오차를 학습하는 과정: 역전파
	4. 가중치가 오차에 얼마나 기여했는지(가중치 기여도 파악 가능)
16. 오차 기여 책임
	1. 오차에 크게 기여 할 수록 많이 업데이트 함
17. 역전파 학습법중 하나-경사 하강법

---
### 동영상
1. 다층 퍼셉트론은 단일 퍼셉트론의 한계를 극복하기 위해서 제안되었다
2. 단일 퍼셉트론->단일 결정 경계 ->비선형 문제 해결 불가
3. 비선형을 해결 하기 위해서 **다층 퍼셉트론 + 활성화 함수** 사용
4. 학습 알고리즘: 역전파
5. 입력,은닉,출력 층으로 구성  
6. 가중치: 이전층과의 연결 강고
7. W_현재층,이전층
8. 여러층의 선형 변환 연산은 결국 하나의 선형 식이 된다->단일 퍼셉트론과 동일하다 -> 활성함수 사용해 해결

## 역전파
- 가중치를 학습시키는 알고리즘
- 오차를 출력 -> 입력 방향으로 전파
- 가중치가 오차에 얼마나 기여했는지를 계산하여 **가중치 업데이트**

#### 기여도 할당 문제
- 오차에 대한 책임을 어떻게 할당할지
- 각각의 가중치가 얼마나 오차에 기여했는지 확인해서 가중치 업데이트

### 오차 기여도를 어떻게 계산하는지(경사 하강법)
- 경사 하강법을 이용해서 오차 기여도 계산
- 미분값이용
- 손실함수: 오차를 정의하는 함수
- 손실함수의 결과: 오차
- 손실함수의 편미분 값: 해당 가중치가 얼마나 오차에 크게 기여했는지
- L: 오차/w: 가중치
$$ dL / dw$$
- 미분값이 크다 -> 오차에 크게 기여했다
- 손실함수의 결과 값을 줄이면서 가중치 업데이트 -> 결과값이 오차이기 때문에 오차가 줄어듬
- 미분값이 그래프의 기울기를 따라가면서 오차를 줄이기 때문에 이름이 경사하강법

### 경사 하강법
$$w_{신} = w_{구} - \eta*(dL\div dw)$$
- 왜 미분값을 빼는 방향으로 업데이트 하는지 
	- 기울기가 음수일 때: w - (-기울기) => w + 기울기 -> w_신 값이 증가->w가 오른쪽으로 이동 -> 에러 감소
	- 기울기가 양수일 때: w - (+기울기) => w - 기울기 -> w_신 값이 감소->w가 왼쪽으로 이동 -> 에러 감소

### MLP 학습 흐름
1. Foward pass를 진행하여 최종 결과값 출력
2. 손실 함수를 이용해 실제 정답과의 손실 계산
3. 손실을 이용해서 가중치 재학습(역전파)
---
