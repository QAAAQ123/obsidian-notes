- 시그모이드 함수 거치면 0~1의 값이 나옴
- CE: 정답 클래스만 계산하면 됨(but 정답이 아닌 클래스도 잘 맞춰야 함)
- 최적화 알고리즘
- 13. 경사 하강법: 데이터 배치 크기에 따라 분류
- 배치 원래 의미: 전체 데이터/미니 배치: 나눠진 데이터
- 배치 경사 => 안정적/확률적 경사=> 데이터에 따라 진행방향이 크게 달라짐
- 미니 배치 => 중간 특징
- 배치 경사 하강법: Local minima에 빠지기 쉽다
- 모멘텀: 과거 기울기의 이동평균을 고려하여 파라미터를 업데이트하는 방법
- 진동 줄이면서 학습 속도도 향상 시킨다
- 관성 벡터 적용해서 업데이트 하면(모멘텀) 2가지 저장
- 모멘텀이 크면 오버슈팅문제 발생 가능성
- 오버슈팅: Gobal minima주변의 기울기가 너무 커서 모멘텀의 속도가 너무 빨라져서 Gobal minima를 지나치는 현상
- NAG(네스테로프 모멘텀): 모멘텀 개선(오버슈팅 문제 완화)/미리 가본뒤에 가중치 업데이트
- 19. 3개 비교
	- SGD: 노이즈가 심해서 학습 속도 느림
		- SGD: 확률적 경사 하강법
	- SGD + 모멘텀: 속도 빨라지지만 비효율적 학습
	- NAG: 학습속도도 빠르고 오버슈팅도 완화
20. 학습률 조정 최적화 방법들(AdaGrad,....)
	1. SGD는 모든 파라미터에 동일한 학습률 적용
	2. AdaGrad: 과거 변화량에 따라 학습률 **개별 적용**
	3. 학습률이 **계속 변함**
21. 제곱: 크기만 알고 싶기 때문에 함
	1. H_t값은 계속 누적됨 -> H_t값 계속 커짐 -> 학습률 지속 감소
22. RMSprop: 최근 경로에 더 큰 비중을 두는 방법(지수 이동평균 사용)
	1. 누적 기울기:\Beta
	2. 최신 기울기: 1 -\Beta
	3. 지수적으로 감소함
23. Adam(아담): 모멘텀 + RMSproop 사용
	1. 가장 많이 사용하는 최적화 알고리즘
	2. 방법: 모멘텀(지수이동 평균) 계산 -> RMSprop 계산
	3. m과 v값을 그대로 사용하지 않고 편향 보정해서 사용함-> 시작점이 0이기 때문에 초기에는 m_hat,v_hat을 크게하고 후기에는 작게 함
	4. Q_t값은 계속 곱해지면서 작아짐 : 0.8 ->0.64 -> 0.xxxx
24. 비교
25. 학습률 감쇠
26. 스텝 감쇠: 일정주기마다 일정 비율
	1. 하이퍼파라미터에 대한 민감도
	2. 학습 과정 비효율(계단식이라서)
---
27. 학습률 감쇠
	1. 학습 초반에는 빠르게 -> 높은 학습률
	2. 후반에는 느리게 -> 낮은 학습률
28. 감쇠방법1: 스텝 감쇠
	1. 일정 주기마다 일정비율로 감소
	2. 각 단계마다 감마의 비율로 학습률 감소시킴
	3. t/d 값이 정수가 될 때마다 감마값에 따라서 학습률 감소
	4. t/d값: 감마값이 하이퍼파라미이다
	5. t: 현재 학습 스텝(epoch)/d: 몇 스텝마다 감소할지 결정(하이퍼파라미터)
	6. 단점
		1. 하이퍼파라미터에 대해서 높은 민감도
		2. 하이퍼파라미터값(d)를 매우 세세하게 조절해야해서 비효율적임
29. 감쇠방법2: 지수 감쇠
	1. 매 epoch마다 지수적으로 감소시키는 방법
	2. 연속적으로 감소
	3. 단점
		1. 감마값(하이퍼파라미터)에 대한 높은 민감도
		2. 지수적으로 감소하기 때문에 학습 후반부에 비효율적인
30. 감쇠방법3: 코사인 소멸
	1. 학습률을 부드럽게 감소시키는 방법 
	2. 감마대신 코사인 사용
	3. T: 전체 학습 epoch
	4. t: 초기에 0이다. 따라서 초기에는 a_t = a_0로 됨(cos(0)=1이다)
	5. 최종적으로 코사인 때문에 학습률이 0이됨
	6. 장점
		1. T값만 정해주면 되어서 쉬운 하이퍼파라미터 설정
		2. 마지막 에폭에 도달하면 0이되기 때문에 시간 효율적
31. 학습률 감쇠는 알맞은 정책을 설정할 수있다
    warmup: 학습률을 매우 작은 값에서부터 점진적으로 증가시키는 방식
	1. 초기 학습이 안정될 때까지 낮은 학습률로 하다가 안정되면 학습률 증가시킴
	2. warmup과 학습률 감쇠 방법 결합하여 사용
	3. 초기학습 불안정 방지
	4. warmup방법2가지 식
		1. 학습률 선형 증가(T_warmup도달할 때까지)
		2. 학습률 지수적 증가-1과 원리 동일
32. 데이터셋 분할: 하이퍼파라미터 설정을 위한 방법
	1. 전체 데이터를 학습 데이터+테스트 데이터로 나눌 수 있음->검증을 위해서
	2. 검증이 좋은 점: 모델의 성능 측정(과적합,과소적합)
	3. 학습 데이터를 학습데이터+검증 데이터로 분리 할 수 있음
	4. 검증 데이터: 중간 점검,하이퍼파라미터 설정하기 위해서
	5. 테스트 데이터: 모델의 최종 성능 검증
33. 데이터셋 분할 방법
	1. 단순 분할: train + test -> 데이터가 너무 적을때
	2. 3-way 분할: train + validation + test -> 대부분의 경우에서 사용
	3. test 데이터는 학습과정에 전혀 관여하지 않는다
34. Validation이 필요한 이유
	1. 단순 분할로 할 경우 단점
		1. 테스트 데이터에만 적합한 하이퍼파라미터가 될 수 있음
	2. Validation을 쓰면 학습 중간에 Validation으로 하이퍼파라미터 결정하고 test데이터로 검증을 함. 이때 하이퍼파라미터가 Validation에만 적합할 경우 하이퍼파라미터를 적절하게 test를 통해 완화시킬수 있음 -> 일반화된 모델 검증,보증 가능
35. Validation활용1: 조기 종료
	1. 검증 데이터의 성능이 향상되지 않을때 학습을 조기에 중단하는 방법
	2. train데이터에만 과적합 되었으면 Validation에서 정답률(정확성)이 감소할것임
	3. validation에서 정확성(Accuracy)이 감소한다면 조기에 종료시켜 과적합되지 않는 모델을 만들 수 있음
최적화 방법,학습률 감쇠 방법,데이터 셋,학습 조기 종료
36. 정규화: 과적합 방지하고 일반화 성능 향상
	1. 노이즈까지 학습하면 과적합 모델이 됨->정규화 사용
37. 정규화 방법1: 패널티 기반 정규화
	1. 가중치 크기에 비례하는 페널티 항 추가
	2. 가중치가 일정 크기 이상 커지지 못하게 패널티 항을 추가함
	3. 가중치가 작은 모델이 되도록 하는게 목적
38. 패널티 기반 정규화2
	1. 가중치 조합은 여러개가 가능하다
	2. 여기서 가중치 크기가 작은 가중치를 찾는 것이 패널티 기반 정규화이다
	3. 가중치가 클수록 출력이 더 커진다 -> 모델이 입력 데이터에 민감해진다
	4. 가중치가 작은 모델은 입력변화에 완만하게 반응 -> 노이즈에 덜 민감하게 반응 -> 더 일반화된 모델 나옴
	5. 가중치의 크기를 제한하는 것이 과적합 문제를 해결해주는 이유: 노이즈에 둔감하게 반응하여 더 일반적인 모델을 만들기 때문에
39. 패널티기반 정규화3
	1. 패널티 식 표현: 최종 가중치 = 가중치 + 패널티 항
	   $$ L'(w) = L(w) + R(w)$$
	2. 패널티 항(R(w)) 정의하는 방법
		1. L1,L2,엘라스틱 넷
	3. L1,L2,엘라스틱 넷을 이해하기 위해서는 Distance개념을 선이해 필요
		1. L1,L2 Distance를 통해서 구성하게 됨
		2. L2 Distance(유클리디안 Distance): 최단 직선 거리
		3. L1 Distance(맨허탄 Distance): 잘 사용되지 않음,2점의 각축의 절댓값의 차이의 절댓값을 더하는 방법(직각 거리)
		4. L1,L2 norm도 많이 사용
			1. norm: 원점에서 다른 점까지의 L1,L2 Distance

